I"ˆÓ<p>Human Activity Recognition (HAR) plays an important role in real life applications primarily dealing with human-centric problems like healthcare and eldercare. It has seen a tremendous growth in the last decade playing a major role in the field of pervasive computing. 
In the recent years, lot of data mining techniques has evolved in analyzing the huge amount of data related to human activity, more specifically, machine learning methods have been been previously employed for recognition include Naive Bayes, SVMs, Threshold-based, Markov chains and deep learning models. Indeed, One important part of the prediction is the selection of suitable models, but also a good selection of relevant features would be benificial in the process of building an accurate model.</p>

<p>In this post, we will try to classify human activity using data captured from embedded inertial sensors, carried by 30 subjects performing activities of daily living. We will extract relevant temporal and spectral features from each signal. Those features are supposed to carry necessary information from each recording.</p>

<h2 id="tutorial-overview">Tutorial overview</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. Data preparation 
2. Features extraction
    2.1. Temporal feaures
    2.2. Spectral features
    2.3 Feature selection
3. Benchmarking SKlearn models
4. Best model Finetuning
5. Results and conclusion
</code></pre></div></div>

<h2 id="1-data-preparation">1. Data preparation</h2>
<p>We will be using the publically available dataset called <a href="https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones">Human Activity Recognition Using Smartphones</a> available in UCI repository. It contains measurements collected from 30 people with age between 19 and 48. The measurements are captured with a smartphone placed on the waist while doing one of the following six activities: walking, walking upstairs, walking downstairs, sitting, standing or laying. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.
The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.</p>

<p>The measures are three-axial linear body acceleration, three-axial linear total acceleration and three-axial angular velocity. So per measurement, the total signal consists of nine component.</p>

<p>Fortunately, The dataset is already prepared and splitted into a training and a test sets for us. In reality, most of the time is spent on fetching, preparing, cleaning the data.
We will split the test dataset to have some data for validation set to serve the finetuning of our classifers, and keep the test set for final classifiers evaluation.</p>

<p>The following script reads the data, and prepares it as a Numpy array. The script is borrowed from <a href="http://ataspinar.com/2018/04/04/machine-learning-with-signal-processing-techniques/">this awesome article</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="n">INPUT_FOLDER_TRAIN</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s">"UCI HAR Dataset/train/Inertial Signals/"</span><span class="p">)</span>
<span class="n">INPUT_FOLDER_TEST</span> <span class="o">=</span>  <span class="n">Path</span><span class="p">(</span><span class="s">"UCI HAR Dataset/test/Inertial Signals/"</span><span class="p">)</span>

<span class="n">INPUT_FILES_TRAIN</span> <span class="o">=</span> <span class="p">[</span><span class="s">'body_acc_x_train.txt'</span><span class="p">,</span> <span class="s">'body_acc_y_train.txt'</span><span class="p">,</span> <span class="s">'body_acc_z_train.txt'</span><span class="p">,</span> 
                     <span class="s">'body_gyro_x_train.txt'</span><span class="p">,</span> <span class="s">'body_gyro_y_train.txt'</span><span class="p">,</span> <span class="s">'body_gyro_z_train.txt'</span><span class="p">,</span>
                     <span class="s">'total_acc_x_train.txt'</span><span class="p">,</span> <span class="s">'total_acc_y_train.txt'</span><span class="p">,</span> <span class="s">'total_acc_z_train.txt'</span><span class="p">]</span>

<span class="n">INPUT_FILES_TEST</span> <span class="o">=</span> <span class="p">[</span><span class="s">'body_acc_x_test.txt'</span><span class="p">,</span> <span class="s">'body_acc_y_test.txt'</span><span class="p">,</span> <span class="s">'body_acc_z_test.txt'</span><span class="p">,</span> 
                     <span class="s">'body_gyro_x_test.txt'</span><span class="p">,</span> <span class="s">'body_gyro_y_test.txt'</span><span class="p">,</span> <span class="s">'body_gyro_z_test.txt'</span><span class="p">,</span>
                     <span class="s">'total_acc_x_test.txt'</span><span class="p">,</span> <span class="s">'total_acc_y_test.txt'</span><span class="p">,</span> <span class="s">'total_acc_z_test.txt'</span><span class="p">]</span>

<span class="n">LABELFILE_TRAIN</span> <span class="o">=</span> <span class="s">'UCI HAR Dataset/train/y_train.txt'</span>
<span class="n">LABELFILE_TEST</span> <span class="o">=</span> <span class="s">'UCI HAR Dataset/test/y_test.txt'</span>

<span class="n">activities_description</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s">'walking'</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s">'walking upstairs'</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">:</span> <span class="s">'walking downstairs'</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">:</span> <span class="s">'sitting'</span><span class="p">,</span>
    <span class="mi">5</span><span class="p">:</span> <span class="s">'standing'</span><span class="p">,</span>
    <span class="mi">6</span><span class="p">:</span> <span class="s">'laying'</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">read_signals</span><span class="p">(</span><span class="n">filepath</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">filepath</span><span class="p">.</span><span class="n">read_text</span><span class="p">().</span><span class="n">splitlines</span><span class="p">()</span>
    <span class="n">data</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="n">rstrip</span><span class="p">().</span><span class="n">lstrip</span><span class="p">().</span><span class="n">split</span><span class="p">(),</span> <span class="n">data</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">line</span><span class="p">))</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="k">def</span> <span class="nf">read_labels</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>        
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
        <span class="n">activities</span> <span class="o">=</span> <span class="n">fp</span><span class="p">.</span><span class="n">read</span><span class="p">().</span><span class="n">splitlines</span><span class="p">()</span>
        <span class="n">activities</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">activities</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">activities</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">randomize</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">permutation</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">labels</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">shuffled_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">permutation</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="n">shuffled_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">permutation</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">shuffled_dataset</span><span class="p">,</span> <span class="n">shuffled_labels</span>

<span class="n">train_signals</span> <span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">input_file</span> <span class="ow">in</span> <span class="n">INPUT_FILES_TRAIN</span><span class="p">:</span>
    <span class="n">signal</span> <span class="o">=</span> <span class="n">read_signals</span><span class="p">(</span><span class="n">INPUT_FOLDER_TRAIN</span> <span class="o">/</span> <span class="n">input_file</span><span class="p">)</span>
    <span class="n">train_signals</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>
<span class="n">train_signals</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_signals</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>


<span class="n">test_signals</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">input_file</span> <span class="ow">in</span> <span class="n">INPUT_FILES_TEST</span><span class="p">:</span>
    <span class="n">signal</span> <span class="o">=</span> <span class="n">read_signals</span><span class="p">(</span><span class="n">INPUT_FOLDER_TEST</span> <span class="o">/</span> <span class="n">input_file</span><span class="p">)</span>
    <span class="n">test_signals</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>
<span class="n">test_signals</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_signals</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

<span class="n">train_labels</span> <span class="o">=</span> <span class="n">read_labels</span><span class="p">(</span><span class="n">LABELFILE_TRAIN</span><span class="p">)</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">read_labels</span><span class="p">(</span><span class="n">LABELFILE_TEST</span><span class="p">)</span>

</code></pre></div></div>

<h2 id="2-features-extraction">2. Features extraction</h2>
<p>Once our data is loaded, we are ready to extract features from it. We will extract two type of features : temporal features which are extracted from the time domain of the signals, and spectral features which are extracted from the frequency domain. We hope that both types carries enough information during our classification task. Most of described and used features are taken from a master thesis that you can enjoy reading <a href="http://sal.aalto.fi/publications/pdf-files/tsep16_public.pdf">here</a>.</p>

<h3 id="21-temporal-features">2.1 Temporal features</h3>
<p>The most obvious way to gain information from a signal is to extract features from its raw representation as a time series. The processed time series can be described throiugh statstical features. Different features describe dierent aspects, so calculating several features from one signal can give comprehensive description of that signal. We will use the following time domain related features:</p>

<p><img src="/img/posts/har-ml/temporal-features.png" alt="Temporal features" /></p>

<p>The mean, the standard deviation and RMS are self-explanatory. Skewness, kurtosis and crest factor as well as L, S and I factors describe the shape of distribution. Skewness measure the symmetry of the distribution which is symmetric about the mean has a skewness close to zero. Kurtosis measure the weight of tails of the distribution. Normal distribution has a kurtosis value close to three, whereas distributions with smaller tails have larger and flatter distributions have smaller values of kurtosis. Crest factor as well as L, S and I factors all describe in their own way, how much the extreme values dier from the rest of the population.</p>

<p>the following function calculate temporal feature from a time series.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">time_features</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">component</span><span class="o">=</span><span class="s">''</span><span class="p">):</span>
    <span class="n">expected_value</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">series</span><span class="p">)</span>
    <span class="n">standard_deviation</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">series</span><span class="p">)</span>
    <span class="n">square_mean_root</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">series</span><span class="p">)))</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">root_mean_square</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">series</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">peak_value</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">series</span><span class="p">)</span>
    <span class="n">skewness</span> <span class="o">=</span> <span class="n">skew</span><span class="p">(</span><span class="n">series</span><span class="p">)</span>
    <span class="n">kurtosiss</span> <span class="o">=</span> <span class="n">kurtosis</span><span class="p">(</span><span class="n">series</span><span class="p">)</span>
    <span class="n">crest_factor</span> <span class="o">=</span> <span class="n">peak_value</span> <span class="o">/</span> <span class="n">root_mean_square</span>
    <span class="n">l_factor</span> <span class="o">=</span> <span class="n">peak_value</span> <span class="o">/</span> <span class="n">square_mean_root</span>
    <span class="n">s_factor</span> <span class="o">=</span> <span class="n">root_mean_square</span> <span class="o">/</span> <span class="n">expected_value</span>
    <span class="n">i_factor</span> <span class="o">=</span> <span class="n">peak_value</span> <span class="o">/</span> <span class="n">expected_value</span>
     
    <span class="k">return</span> <span class="p">{</span>
    <span class="s">'expected_value_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">expected_value</span><span class="p">,</span>
    <span class="s">'standard_deviation_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">standard_deviation</span><span class="p">,</span>
    <span class="s">'square_mean_root_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">square_mean_root</span><span class="p">,</span>
    <span class="s">'root_mean_square_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">root_mean_square</span><span class="p">,</span>
    <span class="s">'peak_value_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">peak_value</span><span class="p">,</span>
    <span class="s">'skewness_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">skewness</span><span class="p">,</span>
    <span class="s">'kurtosiss_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">kurtosiss</span><span class="p">,</span>
    <span class="s">'crest_factor_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">crest_factor</span><span class="p">,</span>
    <span class="s">'l_factor_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">l_factor</span><span class="p">,</span>
    <span class="s">'s_factor_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">s_factor</span><span class="p">,</span> 
    <span class="s">'i_factor_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">i_factor</span><span class="p">,</span> 
<span class="p">}</span>
</code></pre></div></div>

<h3 id="22-spectral-features">2.2 Spectral features</h3>

<p>Spectral features are frequency based features, they are obtained by converting time based signal into frequency domain using <a href="https://www.youtube.com/watch?v=spUNpyF58BY">Fourier Transform</a>. In our case, we will convert our time series using Power Spectral Density which is simply the magnitude squared of the Fourier Transform of a continuos time and finite power signal. It is the quantity of power for each frequency component. More specifically, We use the Welchâ€™s methods for calculating PSD as it reduces the <a href="https://en.wikipedia.org/wiki/Spectral_leakage">spectral leakage</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.signal</span> <span class="kn">import</span> <span class="n">welch</span>

<span class="n">f_s</span> <span class="o">=</span> <span class="mi">50</span>

<span class="k">def</span> <span class="nf">get_psd_values</span><span class="p">(</span><span class="n">y_values</span><span class="p">,</span> <span class="n">f_s</span><span class="p">):</span>
    <span class="n">f_values</span><span class="p">,</span> <span class="n">psd_values</span> <span class="o">=</span> <span class="n">welch</span><span class="p">(</span><span class="n">y_values</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">f_s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">f_values</span><span class="p">,</span> <span class="n">psd_values</span>
</code></pre></div></div>

<p>Some of the used frequency domain features corespond to the time domain feature and they are described in the following picture.</p>

<p><img src="/img/posts/har-ml/spectral-features.png" alt="Spectral features" /></p>

<p>Moreover, we can add other spectral features like <a href="https://en.wikipedia.org/wiki/Spectral_flatness">spectral flatness</a>, spectral rolloff which determines the frequency below which 85% of the spectrumâ€™s energy is located.</p>

<p>All presented features are easy to calculate with python, the following function produces them for a given PSD.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats.mstats</span> <span class="kn">import</span> <span class="n">gmean</span> 
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">kurtosis</span><span class="p">,</span> <span class="n">skew</span>

<span class="k">def</span> <span class="nf">rolloff</span><span class="p">(</span><span class="n">psd</span><span class="p">,</span><span class="n">f</span><span class="p">):</span>
        <span class="n">absSpectrum</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">psd</span><span class="p">)</span>
        <span class="n">spectralSum</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">psd</span><span class="p">)</span>

        <span class="n">rolloffSum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">rolloffIndex</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">psd</span><span class="p">)):</span>
            <span class="n">rolloffSum</span> <span class="o">=</span> <span class="n">rolloffSum</span> <span class="o">+</span> <span class="n">absSpectrum</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">rolloffSum</span> <span class="o">&gt;</span> <span class="p">(</span><span class="mf">0.85</span> <span class="o">*</span> <span class="n">spectralSum</span><span class="p">):</span>
                <span class="n">rolloffIndex</span> <span class="o">=</span> <span class="n">i</span>
                <span class="k">break</span>
        <span class="n">frequency</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="n">rolloffIndex</span> <span class="p">]</span>
        <span class="k">return</span> <span class="n">frequency</span>

<span class="k">def</span> <span class="nf">spectral_features</span><span class="p">(</span><span class="n">psd</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">component</span><span class="o">=</span><span class="s">''</span><span class="p">):</span>
    <span class="n">spec_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">psd</span><span class="p">)</span>
    <span class="n">spec_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">psd</span><span class="p">)</span>
    <span class="n">spec_skewness</span> <span class="o">=</span> <span class="n">skew</span><span class="p">(</span><span class="n">psd</span><span class="p">)</span>
    <span class="n">spec_kurtosiss</span> <span class="o">=</span> <span class="n">kurtosis</span><span class="p">(</span><span class="n">psd</span><span class="p">)</span>
    <span class="n">spec_centroid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">psd</span><span class="p">,</span> <span class="n">f</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">psd</span><span class="p">)</span>
    <span class="n">spec_std_f</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">multiply</span><span class="p">((</span><span class="n">f</span> <span class="o">-</span> <span class="n">spec_centroid</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="n">psd</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">psd</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">spec_rms</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">f</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="n">psd</span><span class="p">)))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">psd</span><span class="p">)))</span>
    <span class="n">spec_flatness</span> <span class="o">=</span> <span class="n">gmean</span><span class="p">(</span><span class="n">psd</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">psd</span><span class="p">)</span>
    <span class="n">spec_rolloff</span> <span class="o">=</span> <span class="n">rolloff</span><span class="p">(</span><span class="n">psd</span><span class="p">,</span><span class="n">f</span><span class="p">)</span>
                       
    <span class="k">return</span> <span class="p">{</span>
        <span class="s">'spec_mean_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">spec_mean</span><span class="p">,</span>
        <span class="s">'spec_std_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">spec_std</span><span class="p">,</span>
        <span class="s">'spec_skewness_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">spec_skewness</span><span class="p">,</span>
        <span class="s">'spec_kurtosiss_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">spec_kurtosiss</span><span class="p">,</span>
        <span class="s">'spec_centroid_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">spec_centroid</span><span class="p">,</span>
        <span class="s">'spec_std_f'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">spec_std_f</span><span class="p">,</span>
        <span class="s">'spec_rms_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">spec_rms</span><span class="p">,</span>
        <span class="s">'spec_flatness_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">spec_flatness</span><span class="p">,</span>
        <span class="s">'spec_rolloff_'</span><span class="o">+</span><span class="n">component</span> <span class="p">:</span> <span class="n">spec_rolloff</span><span class="p">,</span> 
    <span class="p">}</span>
</code></pre></div></div>

<p>For each time series in our datasets, the process of extracting all features, temporal and spectral, will result of 21 feature. In our dataset we have 7352 signal in the training set and 2947 in the test set, each signal with 9 components, which results of 189 features per signal.</p>

<p>Now itâ€™s time to go through our dataset and generate all features and put them in a clean dataframe.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate_all_features</span><span class="p">(</span><span class="n">signals</span><span class="p">):</span>
    <span class="n">all_features</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">signal</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">signals</span><span class="p">):</span>
        <span class="n">signal_features</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">):</span>
            <span class="n">series</span> <span class="o">=</span> <span class="n">signal</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>
            <span class="n">f</span><span class="p">,</span> <span class="n">psd</span> <span class="o">=</span> <span class="n">get_psd_values</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">f_s</span><span class="p">)</span>
            <span class="n">signal_features_cpt</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">spectral_features</span><span class="p">(</span><span class="n">psd</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">signal_id</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)),</span> <span class="o">**</span><span class="n">time_features</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">signal_id</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))}</span>
            <span class="n">signal_features</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">signal_features</span><span class="p">,</span> <span class="o">**</span><span class="n">signal_features_cpt</span><span class="p">}</span>
        <span class="n">all_features</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">signal_features</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_features</span><span class="p">)</span>

<span class="n">df_train</span> <span class="o">=</span> <span class="n">generate_all_features</span><span class="p">(</span><span class="n">train_signals</span><span class="p">)</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">generate_all_features</span><span class="p">(</span><span class="n">test_signals</span><span class="p">)</span>

</code></pre></div></div>

<h2 id="3-benchmarking-different-classifiers">3. Benchmarking different classifiers</h2>

<p>After preparing all the features for the training and test sets, we can now train a classifier to recognize the human activity. We will do a quick benchmark of different available classifier and pick the best one and optimize it further. In addition to XGBoost, our list  includes a collection of classifier from the amazing library scikit-learn.</p>

<p>This script instanciate different classifiers and train them using training data and calculate their score on test set.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">benchmark</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">clf_descr</span><span class="p">):</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
    <span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
    <span class="n">train_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df_test</span><span class="p">)</span>
    <span class="n">test_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">clf_descr</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">train_time</span><span class="p">,</span> <span class="n">test_time</span>


<span class="n">models</span> <span class="o">=</span> <span class="p">[(</span><span class="n">RidgeClassifier</span><span class="p">(</span><span class="n">tol</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s">"lsqr"</span><span class="p">),</span> <span class="s">"Ridge Classifier"</span><span class="p">),</span>
        <span class="p">(</span><span class="n">MLPClassifier</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">),</span> <span class="s">"MLP"</span><span class="p">),</span>
        <span class="p">(</span><span class="n">PassiveAggressiveClassifier</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">),</span> <span class="s">"Passive-Aggressive"</span><span class="p">),</span>
        <span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="s">"kNN"</span><span class="p">),</span>
        <span class="p">(</span><span class="n">xgb</span><span class="p">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">),</span> <span class="s">"XGBoost"</span><span class="p">),</span>
        <span class="p">(</span><span class="n">SGDClassifier</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">0001</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s">"elasticnet"</span><span class="p">),</span> <span class="s">'SGD Classifier'</span><span class="p">),</span>
        <span class="p">(</span><span class="n">NearestCentroid</span><span class="p">(),</span> <span class="s">'Nearest Centroid - Rocchio'</span> <span class="p">)]</span>


<span class="k">for</span> <span class="n">penalty</span> <span class="ow">in</span> <span class="p">[</span><span class="s">"l2"</span><span class="p">,</span> <span class="s">"l1"</span><span class="p">]:</span>
    <span class="n">models</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="n">penalty</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span> <span class="sa">f</span><span class="s">'Linear SVC </span><span class="si">{</span><span class="n">penalty</span><span class="si">}</span><span class="s">'</span><span class="p">))</span>
    <span class="n">models</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">SGDClassifier</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">0001</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">penalty</span><span class="o">=</span><span class="n">penalty</span><span class="p">),</span> <span class="sa">f</span><span class="s">'SGD Classifier </span><span class="si">{</span><span class="n">penalty</span><span class="si">}</span><span class="s">'</span><span class="p">))</span>


<span class="n">results_all</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">clf</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">models</span><span class="p">):</span>
    <span class="n">results_all</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">benchmark</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
</code></pre></div></div>

<p>Once models are trained, we can plot their scores and training time, I have also trained the proposed models using temporal and spectral features to se which set of features could perform better.</p>

<p><img src="/img/posts/har-ml/models-scores.PNG" alt="Classifiers score" /></p>

<p>As itâ€™s expected the ensemble model perform better in this classification task. XGBoost has the highest score, but it took the longest to train.</p>

<h2 id="4-best-model-finetuning--xgboost-tuning-with-hyperopt">4. Best model Finetuning : XGBoost tuning with HyperOpt</h2>
<p>XGBoost has a large number of advanced parameters, which can all affect the quality and speed of our classifier, by quality we mean a model that avoid overfitting and generalize well. To achieve that, we can control model complexity by tweaking max_depth, min_child_weight and gamm parameters, or adding randomness to make training robust to noise with subsample and colsample_bytree. You can read more about XGBoost finetuning <a href="https://www.dataiku.com/learn/guide/code/python/advanced-xgboost-tuning.html">here</a>.</p>

<p>In our case, we will use HyperOpt, a Python library for serial and parallel optimization over search spaces, which may include real-valued, discrete, and conditional dimensions. It allows for simple applications of Bayesian optimization. For more details about this topic, check <a href="https://towardsdatascience.com/an-introductory-example-of-bayesian-optimization-in-python-with-hyperopt-aae40fff4ff0">this detailed post</a>.</p>

<p>The following code defines our parameter search space, an objective function to minimize and trails to store the history of our search.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">hyperopt</span> <span class="kn">import</span> <span class="n">hp</span><span class="p">,</span> <span class="n">tpe</span><span class="p">,</span> <span class="n">STATUS_OK</span><span class="p">,</span> <span class="n">Trials</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">log_loss</span><span class="p">,</span> <span class="n">f1_score</span>
<span class="kn">from</span> <span class="nn">hyperopt.fmin</span> <span class="kn">import</span> <span class="n">fmin</span>

<span class="n">space</span> <span class="o">=</span><span class="p">{</span>
        <span class="s">'n_estimators'</span><span class="p">:</span> <span class="n">hp</span><span class="p">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">'n_estimators'</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
        <span class="s">'learning_rate'</span> <span class="p">:</span> <span class="n">hp</span><span class="p">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'learning_rate'</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.9</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3</span><span class="p">),</span>
        <span class="s">'max_depth'</span><span class="p">:</span> <span class="n">hp</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="s">'max_depth'</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)),</span>
        <span class="s">'min_child_weight'</span><span class="p">:</span> <span class="n">hp</span><span class="p">.</span><span class="n">quniform</span> <span class="p">(</span><span class="s">'min_child'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="s">'alpha'</span>       <span class="p">:</span> <span class="n">hp</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'alpha'</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-6</span> <span class="p">),</span>
        <span class="s">'gamma'</span>      <span class="p">:</span> <span class="n">hp</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'gamma '</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-6</span> <span class="p">),</span>
        <span class="s">'subsample'</span><span class="p">:</span> <span class="n">hp</span><span class="p">.</span><span class="n">uniform</span> <span class="p">(</span><span class="s">'subsample'</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">}</span>

<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">space</span><span class="p">):</span>

    <span class="n">clf</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">space</span><span class="p">[</span><span class="s">'n_estimators'</span><span class="p">]),</span>
                            <span class="n">max_depth</span> <span class="o">=</span> <span class="n">space</span><span class="p">[</span><span class="s">'max_depth'</span><span class="p">],</span>
                            <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">space</span><span class="p">[</span><span class="s">'learning_rate'</span><span class="p">],</span>
                            <span class="n">alpha</span> <span class="o">=</span> <span class="n">space</span><span class="p">[</span><span class="s">'alpha'</span><span class="p">],</span>
                            <span class="n">gamma</span>  <span class="o">=</span> <span class="n">space</span><span class="p">[</span><span class="s">'gamma'</span><span class="p">],</span>
                            <span class="n">min_child_weight</span> <span class="o">=</span> <span class="n">space</span><span class="p">[</span><span class="s">'min_child_weight'</span><span class="p">],</span>
                            <span class="n">subsample</span> <span class="o">=</span> <span class="n">space</span><span class="p">[</span><span class="s">'subsample'</span><span class="p">]</span>
                           <span class="p">)</span>

    <span class="n">eval_set</span>  <span class="o">=</span> <span class="p">[(</span> <span class="n">df_train</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span> <span class="n">X_validation</span><span class="p">,</span> <span class="n">y_validation</span><span class="p">)]</span>

    <span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="n">eval_set</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s">"mlogloss"</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="n">pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_validation</span><span class="p">)</span>
    <span class="n">mlogloss</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_validation</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Loss'</span><span class="p">,</span> <span class="n">mlogloss</span><span class="p">)</span>
    <span class="k">return</span><span class="p">{</span><span class="s">'loss'</span><span class="p">:</span><span class="n">mlogloss</span><span class="p">,</span> <span class="s">'status'</span><span class="p">:</span> <span class="n">STATUS_OK</span> <span class="p">}</span>

<span class="n">trials</span> <span class="o">=</span> <span class="n">Trials</span><span class="p">()</span>
<span class="n">best</span> <span class="o">=</span> <span class="n">fmin</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">space</span><span class="o">=</span><span class="n">space</span><span class="p">,</span>
            <span class="n">algo</span><span class="o">=</span><span class="n">tpe</span><span class="p">.</span><span class="n">suggest</span><span class="p">,</span>
            <span class="n">max_evals</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
            <span class="n">trials</span><span class="o">=</span><span class="n">trials</span><span class="p">)</span>   
</code></pre></div></div>

<p>After finishing the space search for optimal parameters, the best set of paramaters are returned and used to train the best version of our classifier, we provide an evaluation set to track the progress of our modelâ€™s learning. Then, we can plot the classification error and the loss in our predictions.</p>

<p><img src="/img/posts/har-ml/xgboost-loss.PNG" alt="XGBoost loss and error" /></p>

<p>It seems like out model stopped learning after iteration 20, Thus, It would be better to have an early stoping around 20.
One of the advantages of XGBoost is its interpretability through features importance. We can see what are the most useful features for performing predictions on the leaf nodes of our modelsâ€™ estimators.</p>

<p><img src="/img/posts/har-ml/features-importance.png" alt="XGBoost features importance" /></p>

<p>The last three component of our signal seem to have most relevant information when classifying humain activity. 
Now letâ€™s look how our model did with respect to each class in our dataset, this can be summarized in the classification report provided by scikit-learn.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              <span class="n">precision</span>    <span class="n">recall</span>  <span class="n">f1</span><span class="o">-</span><span class="n">score</span>   <span class="n">support</span>

           <span class="mi">1</span>       <span class="mf">0.90</span>      <span class="mf">0.95</span>      <span class="mf">0.92</span>       <span class="mi">496</span>
           <span class="mi">2</span>       <span class="mf">0.92</span>      <span class="mf">0.96</span>      <span class="mf">0.94</span>       <span class="mi">471</span>
           <span class="mi">3</span>       <span class="mf">0.95</span>      <span class="mf">0.86</span>      <span class="mf">0.90</span>       <span class="mi">420</span>
           <span class="mi">4</span>       <span class="mf">0.91</span>      <span class="mf">0.82</span>      <span class="mf">0.86</span>       <span class="mi">491</span>
           <span class="mi">5</span>       <span class="mf">0.85</span>      <span class="mf">0.92</span>      <span class="mf">0.88</span>       <span class="mi">532</span>
           <span class="mi">6</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>       <span class="mi">537</span>

   <span class="n">micro</span> <span class="n">avg</span>       <span class="mf">0.92</span>      <span class="mf">0.92</span>      <span class="mf">0.92</span>      <span class="mi">2947</span>
   <span class="n">macro</span> <span class="n">avg</span>       <span class="mf">0.92</span>      <span class="mf">0.92</span>      <span class="mf">0.92</span>      <span class="mi">2947</span>
<span class="n">weighted</span> <span class="n">avg</span>       <span class="mf">0.92</span>      <span class="mf">0.92</span>      <span class="mf">0.92</span>      <span class="mi">2947</span>
</code></pre></div></div>

<p>We can also look at the famous confusion matrix to evaluate the performance of our classifier on the test set.</p>

<p><img src="/img/posts/har-ml/confusion-matrix.PNG" alt="Confusion matrix" /></p>

<p>Our classifier is able to recognize human activity with a pretty good accuracy across all activities.</p>

<h2 id="5-conclusion">5. Conclusion</h2>
<p>That brings us to the end of this tutorial. We have built a classifier for human activity recognition based on temporal and spectral features extracted from signal data coming from human daily activities. We have experimented with a collection of classifiers and we picked the best one which is, as expcted, XGBoost model. Furthermore, we tried to optimize the XGBoost model by performing the hyper-parameter finetuning using HyperOpt to pick the best parameter of our classifier.</p>

<p>For further experiments, we can try using the entier time series signal data instead of extracting features, and use a time series based classifiers like Hidden Markov Models or Ruccurrent Neural network.</p>
:ET